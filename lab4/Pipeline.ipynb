{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-17T18:19:07.685060645Z",
     "start_time": "2024-01-17T18:19:07.650190644Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Використовуємо інтерфейс pipeline і використовуємо задачу summarixation із моделлю, що натренована на українських текстах "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9ec7b01a817637d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 800/800 [00:00<00:00, 6.36MB/s]\n",
      "model.safetensors: 100%|██████████| 977M/977M [01:38<00:00, 9.95MB/s] \n",
      "2024-01-17 20:20:48.458988: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 20:20:48.459874: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-01-17 20:20:48.911632: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 92160000 exceeds 10% of free system memory.\n",
      "2024-01-17 20:20:49.116838: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 92160000 exceeds 10% of free system memory.\n",
      "2024-01-17 20:20:49.157747: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 92160000 exceeds 10% of free system memory.\n",
      "/home/ikripaka/.local/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "2024-01-17 20:20:51.955800: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 92160000 exceeds 10% of free system memory.\n",
      "2024-01-17 20:20:52.085107: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 92160000 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 431/431 [00:00<00:00, 1.94MB/s]\n",
      "spiece.model: 100%|██████████| 804k/804k [00:00<00:00, 1.18MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.25M/2.25M [00:00<00:00, 3.32MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 74.0/74.0 [00:00<00:00, 194kB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model='ukr-models/uk-summarizer')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T18:21:02.919867235Z",
     "start_time": "2024-01-17T18:19:07.689616607Z"
    }
   },
   "id": "bc7443e104614d86",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Людство вимирає через глобальну екологічну катастрофу на Марсі. Про це йдеться в книжці Колонія від Макса Кідрука, яка вийшла на екрани цього тижня.\n"
     ]
    }
   ],
   "source": [
    "text = \"Колонія від Макса Кідрука -- книжка, де у XXII столітті людство вимирає через глобальну екологічну катастрофу. Група молодих людей з різних країн світу вирушає на Марс, щоб знайти новий дім для людства. Вони повинні подолати безліч труднощів, щоб вижити в жорстокому марсіанському середовищі. Однак їхні проблеми тільки починаються, коли вони дізнаються, що на Марсі вже живуть інші люди, які не поділяють їхніх ідеалів.\"\n",
    "\n",
    "summary = summarizer(text, max_length=110, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "print(summary[0]['summary_text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T18:37:57.875927714Z",
     "start_time": "2024-01-17T18:37:23.002449087Z"
    }
   },
   "id": "be4a97b22eb32a60",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Використовуємо той самий pipeline інтеррфейс, але з іншими параметрами, що заповнює пусте місце <mask>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e627421805d76736"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 615/615 [00:00<00:00, 3.66MB/s]\n",
      "model.safetensors: 100%|██████████| 1.12G/1.12G [01:49<00:00, 10.2MB/s]\n",
      "All PyTorch model weights were used when initializing TFXLMRobertaForMaskedLM.\n",
      "\n",
      "All the weights of TFXLMRobertaForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForMaskedLM for predictions without further training.\n",
      "sentencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:01<00:00, 5.05MB/s]\n",
      "tokenizer.json: 100%|██████████| 9.10M/9.10M [00:01<00:00, 6.82MB/s]\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='xlm-roberta-base')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T18:23:52.073718570Z",
     "start_time": "2024-01-17T18:21:40.490289448Z"
    }
   },
   "id": "1563eeb7c7d95e74",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'score': 0.5613943934440613,\n  'token': 26099,\n  'token_str': 'продукт',\n  'sequence': 'Кефір - це кисломолочний продукт'},\n {'score': 0.04730786010622978,\n  'token': 5,\n  'token_str': '.',\n  'sequence': 'Кефір - це кисломолочний.'},\n {'score': 0.041148845106363297,\n  'token': 32,\n  'token_str': '?',\n  'sequence': 'Кефір - це кисломолочний?'},\n {'score': 0.027815312147140503,\n  'token': 58375,\n  'token_str': 'жир',\n  'sequence': 'Кефір - це кисломолочний жир'},\n {'score': 0.026694169268012047,\n  'token': 2,\n  'token_str': '</s>',\n  'sequence': 'Кефір - це кисломолочний'}]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Кефір - це кисломолочний <mask>\"\n",
    "unmasker(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T18:31:12.648982270Z",
     "start_time": "2024-01-17T18:31:11.826834729Z"
    }
   },
   "id": "e86b3ed79c0cbf65",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a907bd431465d250"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
